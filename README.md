## Базовый MLOps проект в рамках курса "Введение в MLOps" программы ИИ, ВШЭ

Домашнее задание 1 Airflow
Цель: познакомиться с Airflow и научиться строить DAG для автоматизации ML-задачи.

Требования к функционалу:

1. Написать DAG, который реализует простой pipeline:

инициализация (логирование старта работы);
загрузка датасета из интернета (например, Titanic / Iris / Wine);
предобработка данных (train/test split, нормализация или one-hot encoding);
обучение простой модели (LogisticRegression или RandomForest);
вычисление и сохранение метрик.

2. Использовать **XCom** для передачи данных между шагами.

3. Добавить расписание DAG (каждый вторник в 6 утра).

Домашнее задание 2. MLflow: эксперименты и логирование моделей

Требования к функционалу:

1. Создать новый эксперимент в MLflow со своим ФИО. 2. Обучить ≥ 3 моделей на одном датасете (классический мл, легковесные сетки). 3. Для эксперимента использовать **nested runs**:

общий **parent run** (для всего эксперимента);
отдельные **child runs** для каждой модели.
4. Для каждой child-модели:

залогировать метрики (accuracy / ROC-AUC и др.);
залогировать артефакты (файл модели, preprocessing-пайплайн).
5. Зарегистрировать хотя бы одну модель в **MLflow Model Registry**.


Домашнее задание 3 (Финальный проект). End-to-End MLOps c MLflow → Docker → Serving

Требования к функционалу:

1. Обучение и логирование

DAG в Airflow обучает ≥2 моделей на одном датасете (можно классический ML, легковесные сетки).
Логирование метрик, артефактов и самих моделей в MLflow Tracking.
Регистрация модели в MLflow Model Registry под именем `NAME_SURNAME_MODELTYPE`.
2. Выбор лучшей модели

Автоматический выбор по метрике (например, ROC-AUC/F1/MAPE).
Перевод версии в `Staging` или `Production` (правила — на ваше усмотрение).
3. Сборка и публикация Docker-образа

Сборка PyFunc-сервиса с помощью mlflow.
Публикация образа в registry.
4. Сервинг

docker run...
Проверка через `POST`:
JSON-ответ согласно формату MLflow PyFunc (`{"inputs": [[...], [...]]}` или DataFrame-подобный формат).